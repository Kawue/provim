#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
********************************************
Mass spectrometry imaging data export module
********************************************

The module export MSI data from hdf5 database file to 
HDI or BASIS (matlab version) software for subsequent visualization

run python exportmsi.py --help to get info about parameters of the script

"""

import os
if __name__ == "__main__": 
    import sys;
    if sys.byteorder!='little':
        print('Only little endian machines currently supported! bye bye ....');
        quit();

    module_path = os.path.abspath('%s/../..'%os.path.dirname(os.path.realpath(__file__)));
    print(module_path);
    sys.path.append(module_path);
    sys.path.insert(0,module_path)

import time
import numpy as np
import csv    
from basis.io import manageh5db as mh5
from basis.utils.typechecker import is_string 
from basis.utils.cmdline import OptionsHolder
from basis.procconfig import ExportSet_options
from basis.preproc.pfilter import PeakCluster
from basis.utils.timing import tic, toc

def do_export(dbprocpath, filetype, params):
    """
    Reads MSI datasets from individual files (e.g. generated by HDI software)
    and deposits them into hdf5 database file for downstream preprocessing
    
    See module references:    
     
     Args:
         configuration: instance of OptionsHolder preset with ImportSet_options from procconfig containing:
            
            dbprocpath:  The path to a hdf5-based msi database for data export. 
                                            
            filetype:   Export file type. HDI by default  
            
            filepath:   Name of datafile export. It is set to "exported_data__time_stamp_cluster1.h5"
                        by default
                             
    """
        
    
    #print("\n\n***********Starting*************\n");
        
    if is_string(dbprocpath) and os.path.exists(dbprocpath):
        datasets = mh5.get_dataset_names(dbprocpath,dataset_names=[])
        if not datasets:
            print(dbprocpath + ' database file doesn''t contain any MSI datasets')
            return
    else:
        print(str(dbprocpath) + ' database file is not found')
        return
    
    if filetype=='HDI':
        HDIObject = HDIExport(dbprocpath,params)
        HDIObject.export_hdidata(datasets)
    elif filetype=='BASIS_matlab':
        BASISmatObj = BASIS_matlab(dbprocpath,params)
        BASISmatObj.export_basis_matlab()
    
# specifies import of msi files into the hdf5 file               
class HDIExport:
    
    """
    
    **The container containing the choice of methods and parameters for MSI data export**
    
     
    Attributes:
    
        
        exportpath: the export path for HDI compatible deposition of individual MSI data sets.
                                                             
         
    """    
    
    def __init__(self, dbprocpath, params):
        
        exportpath = params['exportpath']
        
        
        if exportpath=='':
            exportpath = os.path.dirname(dbprocpath)
        else:
            try:
                if not os.path.isdir(exportpath):
                    os.makedirs(exportpath)
            except:
                exportpath = os.path.dirname(dbprocpath)
        
        self.exportpath = os.path.join(exportpath,"basisHDI_data__" + time.strftime("%H%M_%d_%m_%Y"))                  
        print('Setting output directory to: \n%s\n' %(self.exportpath))
        
        self.dbprocpath = dbprocpath
        self.__mzline = 3    
        self.__fileext = params['fileext']       
        
    def export_hdidata(self, datasets):
        """
        
        Exports MSI processed data to HDI compatible file format   
        
        """ 
       
        try:
            PeakClusterObj = PeakCluster()
            pathinh5 = PeakCluster.h5pathfinder(datasets[0])
            PeakClusterObj.load_procobj(self.dbprocpath,pathinh5)
            mzclusters = PeakClusterObj.labels
        except:
            mzclusters = []
            
        if len(mzclusters)==0:
            nmzclusters = 1
            try:
                os.makedirs(self.exportpath+'.raw')
            except:
                print('cannot create directory for export: \n%s\n Exiting'%(self.exportpath))
                return
        else:
            nmzclusters = len(np.unique(mzclusters))
            for i in range(nmzclusters):           
                try:
                    os.makedirs(self.exportpath+'_c'+str(i)+'.raw') 
                except:
                    print('cannot create directory for export: \n%s\n Exiting'%(self.exportpath+'_'+str(i)))
                    return
            
        print('\n\n Exporting  HDI compatible data files from %s \n' %self.dbprocpath) 
         
        j = 0
        for datasetid in datasets:
            try:                
                # upload and prepare data
                mz         = np.float32(mh5.load_dataset(self.dbprocpath,datasetid+'/mz'))
                X          = np.float32(mh5.load_dataset(self.dbprocpath,datasetid+'/Sp'))
                hdata      = np.float32(mh5.load_dataset(self.dbprocpath,datasetid+'/hdata'))
                xy         = np.float32(mh5.load_dataset(self.dbprocpath,datasetid+'/xy'))
                
                # hdi header info
                #hdata[:,1] = hdata[:,self.__mzline-1]
                nms,nobs   = X.shape
                array1     = np.arange(1,nobs+1,1)
                array2     = np.ones((nobs))
            
                if (len(mz)==0 or len(X)==0 or len(hdata)==0 or len(xy)==0):
                    print('%s. %s: Corrupt or incomplete data. Export failed.' %(str(j+1),datasetid))
                    continue
                else:                
                    filename = datasetid
                    
                if nmzclusters>1:
                    for i in range(nmzclusters):                    
                        
                        # create file
                        filepath = os.path.join(self.exportpath+'_c'+str(i)+'.raw',filename[1:] + '_c'+str(i) + self.__fileext)
                        ofile = open(filepath,'w')
                        ofid = csv.writer(ofile, delimiter='\t',lineterminator='\n')
                        
                        # arange data
                        imz  = mz[(mzclusters==i)]
                        iX   = X[(mzclusters==i),:]
                        temp = np.vstack((array2,array1))
                        iX   = np.vstack((temp,xy,iX,temp))
                        iX   = iX[1:,:]
                        ihdata = hdata[(mzclusters==i),:]
                        #print(self.__mzline)
                        #print(ihdata)
                        #print(ihdata.shape)
                        ihdata[:,self.__mzline-1] = imz
                        iX     = iX.transpose()
                        ihdata = ihdata.transpose()
                        nrows,nmz = ihdata.shape
                        nsamples,ncols = iX.shape
                        
                        # number of columns
                        rowdata = [None]*ncols
                        rowdata[0] = 'HDI'
                        ofid.writerow(rowdata)
                        for i in range(nrows):
                            rowdata = [None]*ncols
                            if i==0:
                                rowdata[0] = 2
                            rowdata[3:-2] = ihdata[i,:] 
                            ofid.writerow(rowdata)
                            
                        # save data
                        ofid.writerows(list(np.float32(iX)))
                        ofile.close()
                        print('%s. %s: Successfully saved to --> %s' %(str(j+1),datasetid, filepath))
                else:
                    # create file
                    filepath = os.path.join(self.exportpath+'.raw',filename[1:])
                    ofile = open(filepath,'w')
                    ofid = csv.writer(ofile, delimiter='\t',lineterminator='\n')
                    #ofid.writerow(list([filename]))
                    
                    # arange data
                    temp = np.vstack((array2,array1))
                    X    = np.vstack((temp,xy,X,temp))
                    X    = X[1:,:]
                    #hdata[:,self.__mzline-1] = mz
                    X          = X.transpose()
                    hdata     = hdata.transpose()
                    nrows,nmz = hdata.shape
                    nsamples,ncols = X.shape
                        
                    # number of columns
                    rowdata = [None]*ncols
                    rowdata[0] = 'HDI'
                    ofid.writerow(rowdata)
                    for i in range(nrows):
                        rowdata = [None]*ncols
                        if i==0:
                            rowdata[0] = 2
                        rowdata[3:-2] = hdata[i,:] 
                        ofid.writerow(rowdata)
                            
                    ofid.writerows(list(np.float32(X)))
                    ofile.close()
                    print('%s. %s: Successfully saved to --> %s' %(str(j+1),datasetid, filepath))
            except  Exception as inst:
                     print(inst);
                     print('%s. %s: Export failed!' %(str(j+1),datasetid))
            j = j + 1


# specifies import of msi files into the hdf5 file               
class BASIS_matlab:
    
    """
    
    **The container containing the choice of methods and parameters for MSI BASIS export**
   
    Attributes:
        
        __israw: deposits unprocessed data for further processing in matlab-based BASIS if sets to true.
                
    """    
    
    def __init__(self, dbprocpath,params):
        
        self.dbprocpath = dbprocpath
        if params['israw']!=1:
            self.__israw = 0
        else:
            self.__israw = 1
    def export_basis_matlab(self):
        mh5.save_data2matlab(self.dbprocpath,self.__israw)
           

if __name__ == "__main__": 
    tic()
    settings=OptionsHolder(__doc__, ExportSet_options)
    settings.description='Export MSI Data'
    print(settings.program_description)
    settings.parse_command_line_args()
    print(settings.format_parameters())
    print('\nStarting.....')
    settings.do='yes'
    
    #settings.parameters['datapath'] = '/Users/kv/Desktop/test'
    do_export(settings.parameters['h5dbname'], settings.parameters['filetype'], settings.parameters['params'])
    print('\nFinished on %s in'%(time.strftime("%a, %d %b %Y at %H:%M:%S")))   
    toc()
    print(settings.description_epilog)