# -*- coding: utf-8 -*-
"""
********************************************
Mass spectrometry imaging data import module
********************************************

The module deposits MSI data from HDI generated peak picked data files 
to hdf5 based database file for subsequent pre-processing aimed to account 
for various bioanalytical complexities associated with (DESI and MALDI) 
MSI technologies

run python importmsi.py --help to get info about parameters of the script

"""

import os
if __name__ == "__main__": 
    import sys;
    if sys.byteorder!='little':
        print('Only little endian machines currently supported! bye bye ....');
        quit();

    module_path = os.path.abspath('%s/../..'%os.path.dirname(os.path.realpath(__file__)));
    print(module_path);
    #sys.path.append(module_path);
    sys.path.insert(0, module_path)

import time
import h5py
import numpy as np
from pandas import read_csv
import csv    
from basis.io import manageh5db as m5db
import basis.io.mapfiles as mf
from basis.utils.cmdline import OptionsHolder
from basis.procconfig import ImportSet_options
from basis.utils.timing import tic, toc
try:
    from pyimzml.ImzMLParser import ImzMLParser
except:
    print('\nCannot import imzml parser!\n')
from basis.preproc.palign import PeakAlign


def do_import(datafolder, h5dbname = '', filetype = 'HDI', params = {}):
    
    """
    Reads MSI datasets from individual files (e.g. generated by HDI software)
    and deposits them into hdf5 database file for downstream preprocessing
    
    See module references:    
     
     Args:
         
         configuration: instance of OptionsHolder preset with ImportSet_options from procconfig containing:
            
            datafolder: Path to a folder with indidivual MSI data files. All files in the sub-folders
                        of the specified path will be recursively and automatically mapped. The current
                        working directory is set by default. 
                                            
            filetype:   Read file type. HDI by default  
            
         
            params:  {'param1': 'value', 'param2', 'value'} Parameter set for the read file type.
                        
            h5rawdbname:   Name of the newly created database file. It is set to "imported_data__time_stamp.h5"
                        by default
                    
     Returns: 
     
         h5dbname: Generated database h5 file with deposited MSI datasets for pre-processing
         
    """

    if os.path.isdir(datafolder)==False:
        datafolder = os.getcwd()

    
    filereadinfo = params
    print(filereadinfo)
    fInfo = mf.FilesInfo(folderpath=datafolder, fileext=filereadinfo['fileext'])
    fInfo.map_files()
    nfiles = len(fInfo.filepaths)
    if nfiles>0:
        #print("\n\n***********Starting*************\n")
        if nfiles==1:
            print('\n%s %s file found in %s\n' %(str(nfiles), filereadinfo['fileext'], datafolder))
        else:
            print('\n%s %s files found in %s\n' %(str(nfiles), filereadinfo['fileext'], datafolder))
            
        if filetype=='HDI':
            h5Info = HDIImport(h5dbname,datafolder)
            h5Info.import_data(fInfo.filepaths, filereadinfo)
        elif filetype=='imzML':
            h5Info = imzMLImport(h5dbname,datafolder)
            h5Info.import_data(fInfo.filepaths, filereadinfo)
    else:
        print('%s: Failed to find any data files with the extension of %s' %(datafolder,filereadinfo['fileext']))


 # specifies import of msi files into the hdf5 file               
class HDIImport:    
    """    
     **The container containing the choice of methods and parameters for MSI data import**
         
    Attributes:
            
        datapath: the path to a folder with indidivual MSI data files. All files in the sub-folders
                    of the specified path will be recursively and automatically mapped. The current
                    working directory is set by default. 
                                                            
        filetype: the type of imported MSI files, ``HDI`` by default  
             
        params:  the parameter set for the imported file type, ``{'HDI_fileext':'.txt', 'HDI_mzline': 3, 'HDI_delimiter': '\t'}`` 
        
        filename: the name of hdf5 database file for MSI data deposition, by default ``imported_data__timestamp.h5``
        
        mzinfo: the units and range of m/z or ccs feature vectors, by default ``{'mass range': [600, 900], 'units': 'Da'}``
    """    
    
    def __init__(self, filename='',datafolder=''):        
        
        self.filename = ''
        self.folderpath = ''        
        
        if filename!='':
            self.folderpath = os.path.dirname(filename)
            self.filename   = os.path.basename(filename)    
        
        print('Setting database folder to:')
        if self.folderpath == '':
            if os.path.isdir(datafolder):
                self.folderpath=datafolder
            else:
                self.folderpath=os.getcwd()
        try:
            if not os.path.isdir(self.folderpath):
                os.makedirs(self.folderpath);
        except:
            self.folderpath=os.getcwd()
        print(self.folderpath+'\n')
            
        if self.filename == '':
            print('Output file name not supplied. Setting output database file name to:');
            self.filename =  "imported_data__" + time.strftime("%H%M_%d_%m_%Y") +".h5"
            print(self.filename+'\n')
        else:
            self.filename = os.path.splitext(self.filename)[0] + '.h5'
                   
    def import_data(self, filelist, params):
 
        """
        Reads in MSI peak picked data from the HDI output file type     
        """ 
        
        headerlines = 5
        mzline      = params['mzline'] 
        delimiter   = params['delimiter']
        
        if (delimiter=='tab') or (delimiter =='\t'):
            delimiter = '\t'
        elif (delimiter=='comma') or (delimiter ==','):
            delimiter = ','
            
        nfiles    = len(filelist)
        print(os.path.join(self.folderpath, self.filename))
        hf        = h5py.File(os.path.join(self.folderpath, self.filename), 'w')
        nprevelms = -1
        for i in range(0,nfiles):
            filepath = filelist[i]
            try:
                print('%s. %s: Reading...'%(str(i+1), os.path.basename(filepath)))
                
                # exctract header lines adapatively
                fid =  open(filepath)                
                cid = csv.reader(fid,delimiter = delimiter)
                headmat = np.array([])
                nprevelms = -1
                headername = ''
                for i in range(headerlines+5):
                    rowvals = next(cid)
                    if (len(rowvals)>3):
                        try:
                            rowmat = (np.array(rowvals[3:])).astype(np.float32)
                            nelms = len(rowmat)
                            if nprevelms==-1:
                                nprevelms= nelms
                                headmat = rowmat
                            elif nprevelms!=nelms:
                                headerlines=i
                                rowmat = (np.array(rowvals)).astype(np.float32)                                
                                break
                            else:            
                                headmat = np.vstack([headmat,rowmat])
                        except:
                            try:
                                rowmat =  np.array([float(x) for x in rowvals[3:] if x])
                                if len(rowmat)==0:
                                    continue
                                nelms = len(rowmat)
                                if nprevelms==-1:
                                    nprevelms= nelms
                                    headmat = rowmat
                                elif nprevelms!=nelms:
                                    headerlines = i
                                    rowmat      = (np.array(rowvals)).astype(np.float32)                                
                                    break
                                else:            
                                    headmat = np.vstack([headmat,rowmat])
                            except:
                                continue
                    elif len(rowvals)==1:
                        headername = rowvals[0]
                        
                mz      = headmat[mzline-1,]
                nmz     = len(mz)
                mzindcs = mz.ravel().argsort()  
                fid.close()
                
                # exctract intensity data matrix 
                datafile = read_csv(filepath, sep=delimiter, header=headerlines);
                matdata  = datafile.as_matrix()
                matdata  = np.float32(matdata)  
                
                # now add the first row
                matdata = np.vstack([rowmat,matdata])
                dpath   = os.path.splitext(os.path.basename(filepath));
                try:                
                    ginfo    = hf.create_group(dpath[0]);
                    try:
                        print('   %s: Depositing into --> %s'%(os.path.basename(filepath),self.filename))
                        mz   = np.float32(mz[mzindcs]);        
                        
                        # two last columns are attributes of HDI files needs to be removed
                        X        = matdata[:,3:-2]
                        X        = X[:,mzindcs]
                        nObs,nmz = X.shape
                        headmat  = headmat[:,mzindcs] 
                                             
                        # save data into the hdf5 file                                                           
                        m5db.save_dataset(ginfo,'mzraw', data = np.transpose(mz))                                   
                        m5db.save_dataset(ginfo,'Spraw', data = np.transpose(X), compression_opts = 5)
                        m5db.save_dataset(ginfo,'xy',data = np.transpose(matdata[:,[1,2]]))                
                        m5db.save_dataset(ginfo,'hdata',data = np.transpose(headmat))
                        
                        print('Min: %s Max: %s Count > 0: %s'%(np.min(X),np.max(X), np.sum(X > 0.0)));
                        
                        print(len(str(i+1))*' ' +'  %s: Successfully Deposited into --> %s'%(os.path.basename(filepath),self.filename))
                    except:
                        print(len(str(i+1))*' ' +'  %s: Failed to deposit '%(os.path.basename(filepath)))
                except:
                    print(len(str(i+1))*' ' + '  %s: All files must have unique names: Failed to create a dataset in %s'%(os.path.basename(filepath),self.filename))
            except:
                print(len(str(i+1))*' ' + '  %s: Failed to read in' %os.path.basename(filepath))

class imzMLImport:    
    """    
     **The container containing the choice of methods and parameters for MSI data import**
         
    Attributes:
            
        datapath: the path to a folder with indidivual MSI data files. All files in the sub-folders
                    of the specified path will be recursively and automatically mapped. The current
                    working directory is set by default. 
                                                            
        filetype: the type of imported MSI files, ``HDI`` by default  
             
        params:  the parameter set for the imported file type, ``{'HDI_fileext':'.txt', 'HDI_mzline': 3, 'HDI_delimiter': '\t'}`` 
        
        filename: the name of hdf5 database file for MSI data deposition, by default ``imported_data__timestamp.h5``
        
        mzinfo: the units and range of m/z or ccs feature vectors, by default ``{'mass range': [600, 900], 'units': 'Da'}``
    """    
    
    def __init__(self, filename='',datafolder=''):        
        
        self.filename = ''
        self.folderpath = ''        
        
        if filename!='':
            self.folderpath = os.path.dirname(filename)
            self.filename   = os.path.basename(filename)    
        
        print('Setting database folder to:')
        if self.folderpath == '':
            if os.path.isdir(datafolder):
                self.folderpath=datafolder
            else:
                self.folderpath=os.getcwd()
        try:
            if not os.path.isdir(self.folderpath):
                os.makedirs(self.folderpath);
        except:
            self.folderpath=os.getcwd()
        print(self.folderpath+'\n')
            
        if self.filename == '':
            print('Output file name not supplied. Setting output database file name to:');
            self.filename =  "imported_data__" + time.strftime("%H%M_%d_%m_%Y") +".h5"
            print(self.filename+'\n')
        else:
            self.filename = os.path.splitext(self.filename)[0] + '.h5'
                   
    def import_data(self, filelist, params):
 
        """
        Reads in MSI peak picked data from the imzML data file     
        """ 
                    
        nfiles    = len(filelist)
        print(os.path.join(self.folderpath, self.filename))
        hf        = h5py.File(os.path.join(self.folderpath, self.filename), 'w')
        for i in range(0,nfiles):
            filepath = filelist[i]
            dpath   = os.path.splitext(os.path.basename(filepath));
            try:
                print('%s. %s: Reading...'%(str(i+1), os.path.basename(filepath)))
                X, xy, mz, hdata = self.imzml_reader(filepath,params)
                try:                
                    ginfo    = hf.create_group(dpath[0]);
                    try:
                        print('   %s: Depositing into --> %s'%(os.path.basename(filepath),self.filename))
                                                 
                        # save data into the hdf5 file                                                           
                        m5db.save_dataset(ginfo,'mzraw', data = np.transpose(mz))                                   
                        m5db.save_dataset(ginfo,'Spraw', data = np.transpose(X), compression_opts = 5)
                        m5db.save_dataset(ginfo,'xy',data = np.transpose(xy))                
                        m5db.save_dataset(ginfo,'hdata',data = np.transpose(hdata))
                        print('Min: %s Max: %s Count > 0: %s'%(np.min(X),np.max(X), np.sum(X > 0.0)));
                            
                        print(len(str(i+1))*' ' +'  %s: Successfully Deposited into --> %s'%(os.path.basename(filepath),self.filename))
                    except:
                        print(len(str(i+1))*' ' +'  %s: Failed to deposit '%(os.path.basename(filepath)))
                except:
                    print(len(str(i+1))*' ' + '  %s: All files must have unique names: Failed to create a dataset in %s'%(os.path.basename(filepath),self.filename))
            except:
                print(len(str(i+1))*' ' + '  %s: Failed to read in' %os.path.basename(filepath))
                
        
    def imzml_reader(self,filepath,params):
        """
            Reads MSI peak picked data from the imzML file type 
            
            Parameters
            
                mzmaxshift: maximum peak shift in respective (ppm or Da) units
                mzbinsize:  bin size for histogram-resolution 
                mzunits:    ppm or Da units
        
        """ 

        imzfile       = ImzMLParser(filepath, parse_lib='ElementTree')
        n_intensities = sum(imzfile.intensityLengths)
        #print('n_intensities %s'%n_intensities)
        sp_indcs      = np.concatenate((np.array([0]),np.cumsum(imzfile.intensityLengths)))
        
        mz = np.zeros(n_intensities)
        sp = np.zeros(n_intensities)
        
        index = 0
        for idx, (x,y,z) in enumerate(imzfile.coordinates):
            imz, isp = imzfile.getspectrum(idx)
            #print("x,y,z: %s,%s,%s"%(x,y,z))
            sp[sp_indcs[index]:sp_indcs[index+1]] = isp
            #print('isp: Min: %s Max: %s Count > 0: %s'%(np.min(isp),np.max(isp), np.sum(isp > 0.0)));
            mz[sp_indcs[index]:sp_indcs[index+1]] = imz
            #print('imz: Min: %s Max: %s Count > 0: %s'%(np.min(imz),np.max(imz), np.sum(imz > 0.0)));
            index  = index + 1
        
        
        
        mz = mz[sp>0]
        sp = sp[sp>0]
        
        #print('sp: Min: %s Max: %s Count > 0: %s'%(np.min(sp),np.max(sp), np.sum(np.array(sp) > 0.0)));
        
        if (params['mzunits']=='Da') or (params['mzunits']=='ppm'):
                 mzres = params['cmzbinsize']
        else:
            print('Error: m/z need to be in Da or ppm units')
        
        # perform calculation of common mass to charge feature vector
        peakalign_obj = PeakAlign()
        cmz = peakalign_obj.get_reference(mz, mzres, params['mzmaxshift'], params['mzunits'])
        
        
        nmz = len(cmz)
        nsp = len(imzfile.intensityLengths)
        X   = np.zeros([nsp,nmz])
        xy  = np.zeros([nsp,3])
        
        # perform matching of individual m/z species to the common mass to charge (cmz) vector
        index = 0 
        if params['mzunits']=='ppm':
            cmz = peakalign_obj.to_ppm(np.array(cmz))
            
        for idx, (x,y,z) in enumerate(imzfile.coordinates):
            imz, isp = imzfile.getspectrum(idx)
            if params['mzunits']=='ppm':
               imz = peakalign_obj.to_ppm(np.array(imz))    
               
            refmzidcs, mzindcs = peakalign_obj.pmatch_nn(cmz,np.array(imz),params['mzmaxshift'])
            if len(refmzidcs)>0:
                X[index,refmzidcs] = np.array(isp)[mzindcs]
            xy[index,:]        = [x,y,z]
            index = index + 1 
            
        if params['mzunits']=='ppm':
            cmz = peakalign_obj.to_mz(cmz)
        
        rankx = np.argsort(np.sum(X,axis = 0))
        padding = np.zeros(cmz.shape); #this is to introduce rows normally not present in imzML, but used in HDI
        hdata = np.vstack((padding, rankx, cmz, padding))
        
        
        return X, xy, cmz, hdata
    
    
if __name__ == "__main__": 
    tic()
    settings=OptionsHolder(__doc__, ImportSet_options);
    settings.description='Import Raw Data'
    print(settings.program_description)
    settings.parse_command_line_args()
    #settings.parameters['filetype'] = 'imzML'
    #settings.parameters['datapath'] = '/Users/kv/Desktop/testMSIdata'
    #settings.parameters['filereadinfo'] = {'fileext': '.imzML','cmzbinsize': 5, 'mzmaxshift':50, 'mzunits': 'ppm'}
    print(settings.format_parameters())
    print('\nStarting.....')
    settings.do='yes'
    
    do_import(settings.parameters['datapath'], settings.parameters['h5rawdbname'], settings.parameters['filetype'], settings.parameters['filereadinfo'])
    print('\nFinished on %s in'%(time.strftime("%a, %d %b %Y at %H:%M:%S")));   
    toc()    
    print(settings.description_epilog);